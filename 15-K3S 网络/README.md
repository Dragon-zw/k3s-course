Video Referenceï¼š[15-ç½‘ç»œ](https://www.bilibili.com/video/BV1tZ4y1f7Bb/?spm_id_from=333.788&vd_source=9560c118fae1db9638f05a6ba2527085)

GitHub README.mdï¼š[15-ç½‘ç»œ](https://github.com/kingsd041/k3s-tutorial/tree/main/15-ç½‘ç»œ)

å®˜æ–¹æ–‡æ¡£èµ„æ–™ï¼šhttps://docs.k3s.io/zh/networking

# 1 ç½‘ç»œ

æœ¬èŠ‚è¯¾ä»‹ç»äº† `CoreDNS`ã€`Traefik Ingress` æ§åˆ¶å™¨å’Œ `Klipper service load balancer` å¦‚ä½•åœ¨ K3s ä¸­å·¥ä½œã€‚

å…³äº Flannel é…ç½®é€‰é¡¹å’Œåç«¯é€‰æ‹©ï¼Œæˆ–å¦‚ä½•è®¾ç½®è‡ªå·±çš„ CNIï¼Œè¯·å‚è€ƒ [å®‰è£…ç½‘ç»œé€‰é¡¹](http://docs.rancher.cn/docs/k3s/installation/network-options/_index) é¡µé¢ã€‚

å…³äº K3s éœ€è¦å¼€æ”¾å“ªäº›ç«¯å£ï¼Œè¯·å‚è€ƒ [å®‰è£…è¦æ±‚](http://docs.rancher.cn/docs/k3s/installation/installation-requirements/_index#ç½‘ç»œ)ã€‚

K3s server éœ€è¦ 6443 ç«¯å£æ‰èƒ½è¢«æ‰€æœ‰èŠ‚ç‚¹è®¿é—®ã€‚

å½“ä½¿ç”¨ Flannel VXLAN æ—¶ï¼ŒèŠ‚ç‚¹éœ€è¦èƒ½å¤Ÿé€šè¿‡ UDP ç«¯å£ 8472 è®¿é—®å…¶ä»–èŠ‚ç‚¹ï¼Œæˆ–è€…å½“ä½¿ç”¨ Flannel Wireguard åç«¯æ—¶ï¼ŒèŠ‚ç‚¹éœ€è¦èƒ½å¤Ÿé€šè¿‡ UDP ç«¯å£ 51820 å’Œ 51821ï¼ˆä½¿ç”¨ IPv6 æ—¶ï¼‰è®¿é—®å…¶ä»–èŠ‚ç‚¹ã€‚è¯¥èŠ‚ç‚¹ä¸åº”ä¾¦å¬ä»»ä½•å…¶ä»–ç«¯å£ã€‚ K3s ä½¿ç”¨åå‘éš§é“ï¼Œä»¥ä¾¿èŠ‚ç‚¹ä¸æœåŠ¡å™¨å»ºç«‹å‡ºç«™è¿æ¥ï¼Œå¹¶ä¸”æ‰€æœ‰ kubelet æµé‡éƒ½é€šè¿‡è¯¥éš§é“è¿è¡Œã€‚ä½†æ˜¯ï¼Œå¦‚æœä½ ä¸ä½¿ç”¨ Flannel å¹¶æä¾›è‡ªå·±çš„è‡ªå®šä¹‰ CNIï¼Œé‚£ä¹ˆ K3s ä¸éœ€è¦ Flannel æ‰€éœ€çš„ç«¯å£ã€‚

å¦‚æœè¦ä½¿ç”¨metrics serverï¼Œåˆ™éœ€è¦åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šæ‰“å¼€ç«¯å£ 10250 ç«¯å£ã€‚

å¦‚æœè®¡åˆ’ä½¿ç”¨åµŒå…¥å¼ etcd å®ç°é«˜å¯ç”¨æ€§ï¼Œåˆ™ server èŠ‚ç‚¹å¿…é¡»åœ¨ç«¯å£ 2379 å’Œ 2380 ä¸Šå¯ä»¥ç›¸äº’è®¿é—®ã€‚

##### ğŸ’¡é‡è¦

èŠ‚ç‚¹ä¸Šçš„ VXLAN ç«¯å£ä¸åº”å…¬å¼€æš´éœ²ï¼Œå› ä¸ºå®ƒå…¬å¼€äº†é›†ç¾¤ç½‘ç»œï¼Œä»»ä½•äººéƒ½å¯ä»¥è®¿é—®å®ƒã€‚åº”åœ¨ç¦æ­¢è®¿é—®ç«¯å£ 8472 çš„é˜²ç«å¢™/å®‰å…¨ç»„åé¢è¿è¡ŒèŠ‚ç‚¹ã€‚

**âš ï¸è­¦å‘Šï¼š** Flannel ä¾é  [Bridge CNI plugin](https://www.cni.dev/plugins/current/main/bridge/) æ¥åˆ›å»ºä¸€ä¸ªå¯ä»¥äº¤æ¢æµé‡çš„ L2 ç½‘ç»œã€‚å…·æœ‰ NET_RAW åŠŸèƒ½çš„ Rogue pod å¯ä»¥æ»¥ç”¨è¯¥ L2 ç½‘ç»œæ¥å‘åŠ¨æ”»å‡»ï¼Œå¦‚ [ARP æ¬ºéª—](https://static.sched.com/hosted_files/kccncna19/72/ARP DNS spoof.pdf)ã€‚å› æ­¤ï¼Œæ­£å¦‚ [kubernetes æ–‡æ¡£](https://kubernetes.io/docs/concepts/security/pod-security-standards/)ä¸­è®°è½½çš„é‚£æ ·ï¼Œè¯·è®¾ç½®ä¸€ä¸ªå—é™é…ç½®æ–‡ä»¶ï¼Œåœ¨ä¸å¯ä¿¡ä»»çš„ pod ä¸Šç¦ç”¨ NET_RAWã€‚

| **åè®®** | **ç«¯å£**  | **æº**                   | **æè¿°**                                      |
| -------- | --------- | ------------------------ | --------------------------------------------- |
| TCP      | 6443      | K3s agent èŠ‚ç‚¹           | Kubernetes API Server                         |
| UDP      | 8472      | K3s server å’Œ agent èŠ‚ç‚¹ | ä»…å¯¹ Flannel VXLAN éœ€è¦                       |
| UDP      | 51820     | K3s server å’Œ agent èŠ‚ç‚¹ | åªæœ‰ Flannel Wireguard åç«¯éœ€è¦               |
| UDP      | 51821     | K3s server å’Œ agent èŠ‚ç‚¹ | åªæœ‰ä½¿ç”¨ IPv6 çš„ Flannel Wireguard åç«¯æ‰éœ€è¦ |
| TCP      | 10250     | K3s server å’Œ agent èŠ‚ç‚¹ | Kubelet metrics                               |
| TCP      | 2379-2380 | K3s server èŠ‚ç‚¹          | åªæœ‰åµŒå…¥å¼ etcd é«˜å¯ç”¨æ‰éœ€è¦                  |

## 1.1 ğŸ’CoreDNS

CoreDNS æ˜¯åœ¨ agent èŠ‚ç‚¹å¯åŠ¨æ—¶éƒ¨ç½²çš„ã€‚è¦ç¦ç”¨ï¼Œè¯·åœ¨æ¯å°æœåŠ¡å™¨ä¸Šè¿è¡Œ `--disable coredns` é€‰é¡¹ã€‚

å¦‚æœä½ ä¸å®‰è£… CoreDNSï¼Œä½ å°†éœ€è¦è‡ªå·±å®‰è£…ä¸€ä¸ªé›†ç¾¤ DNS æä¾›å•†[ éœ€è¦æ‰‹åŠ¨éƒ¨ç½² CoreDNSï¼Œä¸€èˆ¬å®é™…ä½¿ç”¨å¹¶ä¸ä¼šç¦ç”¨ CoreDNS åŠŸèƒ½ ]ã€‚

### 1.1.1 å¦‚ä½•ä¿®æ”¹ coredns å‚æ•°

é€šè¿‡ä¿®æ”¹`/var/lib/rancher/k3s/server/manifests/coredns.yaml`é…ç½®æ–‡ä»¶ä¼šç«‹å³ç”Ÿæ•ˆï¼Œä½†é‡å¯ K3s æœåŠ¡ä¼šå¯¼è‡´ coredns é…ç½®é‡æ–°åˆå§‹åŒ–ï¼Œæ‰€ä»¥è¦ä¿®æ”¹ corends çš„å‚æ•°ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ­¥éª¤ä¿®æ”¹ï¼š

1. å°†`coredns.yaml`ä¿å­˜åˆ°å…¶ä»–ç›®å½•
2. é€šè¿‡ `--disable coredns` ç¦ç”¨ `coredns`
3. å°†å¤‡ä»½çš„`coredns.yaml` å¤åˆ¶åˆ° `/var/lib/rancher/k3s/server/manifests/c.yaml`ï¼Œå¹¶ä¿®æ”¹å¯¹åº”å‚æ•°

```shell
# K3s Master
$ curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \
  INSTALL_K3S_MIRROR=cn \
  INSTALL_K3S_EXEC="--docker" \
  INSTALL_K3S_VERSION="v1.21.14+k3s1" \
  K3S_TOKEN="rancher" sh -

# æŸ¥çœ‹NodeçŠ¶æ€
$ kubectl get nodes
NAME   STATUS   ROLES                  AGE   VERSION
k3s1   Ready    control-plane,master   28s   v1.21.14+k3s1

# æŸ¥çœ‹Tokenä¿¡æ¯
$ cat /var/lib/rancher/k3s/server/token
K10436aaa99ab2808a8a33f8737e0aea5bad9ed3a3afbababb11e68e982261f065a::server:rancher

# K3s Worker
$ curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \
  INSTALL_K3S_MIRROR=cn \
  K3S_URL=https://10.0.0.51:6443 \
  K3S_TOKEN=rancher \
  INSTALL_K3S_VERSION="v1.21.14+k3s1" \
  INSTALL_K3S_EXEC="--node-ip=10.0.0.52" \
  sh -

# æŸ¥çœ‹NodeçŠ¶æ€
$ kubectl get nodes
NAME   STATUS   ROLES                  AGE     VERSION
k3s1   Ready    control-plane,master   3m49s   v1.21.14+k3s1
k3s2   Ready    <none>                 28s     v1.21.14+k3s1

# ä¿®æ”¹coredns.yamlæ–‡ä»¶
$ cd /var/lib/rancher/k3s/server/manifests
# cp -av /var/lib/rancher/k3s/server/manifests/coredns.yaml /var/lib/rancher/k3s/server/manifests/c.yaml
$ vim coredns.yaml
[......]
Corefile: |
    .:53 {
        hosts /etc/coredns/NodeHosts {
          ttl 60
          reload 15s
          10.0.0.51 k3s.test.org
          fallthrough
        }
[......]

# ä¿å­˜æ–‡ä»¶ä¹‹åï¼Œå°±ä¼šç±»ä¼¼äº kubectl apply -f coredns.yaml é‡æ–°å¼•ç”¨è¯¥é…ç½®æ–‡ä»¶
# kubectl get configmap coredns -n kube-system -o yaml
```

![img](https://cdn.nlark.com/yuque/0/2023/png/2555283/1679577260163-62184ba1-ca2e-4451-a0e5-911059dc5c5b.png)

èŒƒä¾‹ï¼šåˆ›å»ºä¸€ä¸ª Nginx Pod è¿›è¡Œæµ‹è¯•

```shell
# ä¸‹è½½é•œåƒ(Containerd)
$ ctr images pull --all-platforms docker.io/kingsd/nginx:install-tools
# ä¸‹è½½é•œåƒ(Docker)
$ docker pull docker.io/kingsd/nginx:install-tools

# è¿è¡ŒPodå¹¶æŸ¥çœ‹Podçš„çŠ¶æ€
$ kubectl run nginx --image=kingsd/nginx:install-tools
$ kubectl get pod -o wide
NAME    READY   STATUS    RESTARTS   AGE   IP          NODE   NOMINATED NODE   READINESS GATES
nginx   1/1     Running   0          69s   10.42.1.3   k3s2   <none>           <none>

$ kubectl exec -it nginx -- ping -c 1 -W 1 k3s.test.org
PING k3s.test.org (10.0.0.51) 56(84) bytes of data.
64 bytes from master01 (10.0.0.51): icmp_seq=1 ttl=63 time=2.69 ms

--- k3s.test.org ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 2.692/2.692/2.692/0.000 ms
```

- å½“é‡å¯ k3s é›†ç¾¤æ—¶ï¼Œä¼šå°†ä¿®æ”¹åçš„`coredns.yaml`é…ç½®æ–‡ä»¶è¿›è¡Œé‡æ–°åˆå§‹åŒ–æˆç³»ç»Ÿé»˜è®¤çš„é…ç½®ã€‚

```shell
# é‡å¯k3sæœåŠ¡
$ systemctl restart k3s.service
# é‡æ–°æŸ¥çœ‹ä¹‹åå°±å˜æˆé»˜è®¤é…ç½®
$ cat /var/lib/rancher/k3s/server/manifests/coredns.yaml

# ä¸ºäº†æ–¹ä¾¿åç»­çš„å®éªŒï¼Œå°†è¯¥coredns.yamlæ‹·è´åˆ°/tmpä¸‹
$ cp -av /var/lib/rancher/k3s/server/manifests/coredns.yaml /tmp/cdns.yaml
```

- æ­£ç¡®çš„åšæ³•

```shell
# ç¦ç”¨corednsçš„åŠŸèƒ½
$ curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \
  INSTALL_K3S_MIRROR=cn \
  INSTALL_K3S_EXEC="--disable coredns --docker" \
  INSTALL_K3S_VERSION="v1.21.14+k3s1" \
  K3S_TOKEN="rancher" sh -

# ä¼šå‘ç°å·²ç»æ²¡æœ‰è¯¥coredns.yamlé…ç½®æ–‡ä»¶
$ ls -l /var/lib/rancher/k3s/server/manifests
total 16
-rw------- 1 root root 1108 Mar 23 21:26 ccm.yaml
-rw------- 1 root root 3645 Mar 23 21:26 local-storage.yaml
drwx------ 2 root root  227 Mar 23 18:29 metrics-server
-rw------- 1 root root 1039 Mar 23 21:26 rolebindings.yaml
-rw------- 1 root root 1098 Mar 23 21:26 traefik.yaml

# å¯ä»¥æŸ¥çœ‹Podçš„è¿è¡Œæƒ…å†µ
$ kubectl get pod --all-namespaces
# ç¼–è¾‘ cdns.yaml æ–‡ä»¶
# ç±»ä¼¼äºæ‰‹åŠ¨éƒ¨ç½² CoreDNS çš„æ–¹å¼
$ vim /tmp/cdns.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: coredns
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: system:coredns
rules:
- apiGroups:
  - ""
  resources:
  - endpoints
  - services
  - pods
  - namespaces
  verbs:
  - list
  - watch
- apiGroups:
  - discovery.k8s.io
  resources:
  - endpointslices
  verbs:
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: system:coredns
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:coredns
subjects:
- kind: ServiceAccount
  name: coredns
  namespace: kube-system
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: coredns
  namespace: kube-system
data:
  Corefile: |
    .:53 {
        errors
        health
        ready
        kubernetes cluster.local in-addr.arpa ip6.arpa {
          pods insecure
          fallthrough in-addr.arpa ip6.arpa
        }
        hosts /etc/coredns/NodeHosts {
          ttl 60
          reload 15s
          10.0.0.51 k3s.test.org
          fallthrough
        }
        prometheus :9153
        forward . /etc/resolv.conf
        cache 30
        loop
        reload
        loadbalance
    }
  NodeHosts: |
    10.0.0.51 k3s1
    10.0.0.52 k3s2
# éœ€è¦æ³¨æ„æ·»åŠ  NodeHostså¦åˆ™éƒ¨ç½²DNSä¼šå¤±è´¥
# å…¶å®NodeHostsåœ¨å¯åŠ¨K3sé›†ç¾¤ä¹‹åï¼Œä¼šé»˜è®¤ç”Ÿæˆkeyï¼Œå› ä¸ºè¿™å°±æ˜¯å¯¹åº”IPåœ°å€å’Œå¯¹åº”çš„ä¸»æœºå
# ä¸æ‰‹åŠ¨åˆ›å»ºNodeHosts keyçš„è¯ä¼šåˆ›å»ºå¤±è´¥ï¼ŒåŸå› å°±æ˜¯æ‰¾åˆ°è¯¥NodeHosts key
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: coredns
  namespace: kube-system
  labels:
    k8s-app: kube-dns
    kubernetes.io/name: "CoreDNS"
spec:
  #replicas: 1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  selector:
    matchLabels:
      k8s-app: kube-dns
  template:
    metadata:
      labels:
        k8s-app: kube-dns
    spec:
      priorityClassName: "system-cluster-critical"
      serviceAccountName: coredns
      tolerations:
        - key: "CriticalAddonsOnly"
          operator: "Exists"
        - key: "node-role.kubernetes.io/control-plane"
          operator: "Exists"
          effect: "NoSchedule"
        - key: "node-role.kubernetes.io/master"
          operator: "Exists"
          effect: "NoSchedule"
      nodeSelector:
        beta.kubernetes.io/os: linux
      containers:
      - name: coredns
        image: rancher/mirrored-coredns-coredns:1.9.1
        imagePullPolicy: IfNotPresent
        resources:
          limits:
            memory: 170Mi
          requests:
            cpu: 100m
            memory: 70Mi
        args: [ "-conf", "/etc/coredns/Corefile" ]
        volumeMounts:
        - name: config-volume
          mountPath: /etc/coredns
          readOnly: true
        ports:
        - containerPort: 53
          name: dns
          protocol: UDP
        - containerPort: 53
          name: dns-tcp
          protocol: TCP
        - containerPort: 9153
          name: metrics
          protocol: TCP
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            add:
            - NET_BIND_SERVICE
            drop:
            - all
          readOnlyRootFilesystem: true
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 1
          successThreshold: 1
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: 8181
            scheme: HTTP
          initialDelaySeconds: 0
          periodSeconds: 2
          timeoutSeconds: 1
          successThreshold: 1
          failureThreshold: 3
      dnsPolicy: Default
      volumes:
        - name: config-volume
          configMap:
            name: coredns
            items:
            - key: Corefile
              path: Corefile
            - key: NodeHosts
              path: NodeHosts
---
apiVersion: v1
kind: Service
metadata:
  name: kube-dns
  namespace: kube-system
  annotations:
    prometheus.io/port: "9153"
    prometheus.io/scrape: "true"
  labels:
    k8s-app: kube-dns
    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: "CoreDNS"
spec:
  selector:
    k8s-app: kube-dns
  clusterIP: 10.43.0.10
  ports:
  - name: dns
    port: 53
    protocol: UDP
  - name: dns-tcp
    port: 53
    protocol: TCP
  - name: metrics
    port: 9153
    protocol: TCP
# æ³¨æ„ä¸èƒ½å°†c_dns.yamlä¿®æ”¹ä¸ºcoredns.yamlæ–‡ä»¶ï¼Œå¦åˆ™K3sä¼šè®¤ä¸ºæ˜¯ç³»ç»Ÿåˆå§‹åŒ–çš„é»˜è®¤é…ç½®æ–‡ä»¶
# ç”±äºæ˜¯"--disable coredns"ï¼Œæ‰€ä»¥è‹¥å‘½åä¸ºcoredns.yamlï¼ŒK3sé‡å¯æœåŠ¡åä¼šåˆ é™¤è¯¥æ–‡ä»¶
$ cp -av /tmp/cdns.yaml /var/lib/rancher/k3s/server/manifests/
$ ls -l /var/lib/rancher/k3s/server/manifests/
total 24
-rw------- 1 root root 1108 Mar 23 21:26 ccm.yaml
-rw------- 1 root root 4483 Mar 23 21:31 cdns.yaml
-rw------- 1 root root 3645 Mar 23 21:26 local-storage.yaml
drwx------ 2 root root  227 Mar 23 18:29 metrics-server
-rw------- 1 root root 1039 Mar 23 21:26 rolebindings.yaml
-rw------- 1 root root 1098 Mar 23 21:26 traefik.yaml

# æŸ¥çœ‹æ˜¯å¦å·²ç»åˆ›å»ºå¥½corednsçš„Pod
$ kubectl get pod --all-namespaces | grep coredns
kube-system   coredns-574bcc6c46-znlzf                  1/1     Running     0          5m17s

# è¿›è¡Œæµ‹è¯•
$ kubectl run nginx --image=kingsd/nginx:install-tools
$ kubectl get pod -o wide
NAME    READY   STATUS    RESTARTS   AGE   IP          NODE   NOMINATED NODE   READINESS GATES
nginx   1/1     Running   0          17m   10.42.0.9   k3s1   <none>           <none>

$ kubectl exec -it nginx -- ping -c 1 -W 1 k3s.test.org
PING k3s.test.org (10.0.0.51) 56(84) bytes of data.
64 bytes from ip-10-0-0-51 (10.0.0.51): icmp_seq=1 ttl=63 time=1.14 ms

--- k3s.test.org ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 1.147/1.147/1.147/0.000 m

# é‡å¯K3sé›†ç¾¤æœåŠ¡ï¼ŒæŸ¥çœ‹é…ç½®æ˜¯å¦ä¼šåˆå§‹åŒ–é…ç½®
$ systemctl restart k3s.service
# ä¼šå‘ç°å¹¶ä¸ä¼šå¯¹corednsçš„é…ç½®åšä¿®æ”¹
$ cat /var/lib/rancher/k3s/server/manifests/cdns.yaml
```

## 1.2 ğŸ’Traefik Ingress Controller

åœ¨ K3s ä¸­ï¼Œå†…ç½®äº† Traefik ä½œä¸ºé›†ç¾¤çš„é»˜è®¤åå‘ä»£ç†å’Œ Ingress Controllerã€‚K3s 1.21 å¼€å§‹é»˜è®¤å®‰è£… Traefik v2ï¼Œè€Œä¹‹å‰çš„ç‰ˆæœ¬åˆ™é»˜è®¤å®‰è£… Traefik v1ã€‚æœ¬æ–‡å°†æ ¹æ®ä¸åŒçš„ Traefik ç‰ˆæœ¬æ¥ä»‹ç»å¦‚ä½•å¯ç”¨ Traefik Dashboradã€‚

Traefik æ˜¯ä¸€ä¸ªäº‘åŸç”Ÿçš„æ–°å‹çš„ HTTP åå‘ä»£ç†ã€[è´Ÿè½½å‡è¡¡](https://cloud.tencent.com/product/clb?from=10680)è½¯ä»¶ï¼Œèƒ½è½»æ˜“çš„éƒ¨ç½²å¾®æœåŠ¡ã€‚k3s å°†å…¶ä½œä¸ºé›†ç¾¤çš„é»˜è®¤åå‘ä»£ç† å’Œ Ingress Controllerï¼Œä½†å¯è§†åŒ–é¢æ¿æ˜¯æ— æ³•è®¿é—®çš„ã€‚

å¯åŠ¨ server æ—¶ï¼Œé»˜è®¤æƒ…å†µä¸‹ä¼šéƒ¨ç½² Traefikã€‚é»˜è®¤çš„é…ç½®æ–‡ä»¶åœ¨`/var/lib/rancher/k3s/server/manifests/traefik.yaml`ä¸­ï¼Œå¯¹è¯¥æ–‡ä»¶çš„ä»»ä½•ä¿®æ”¹éƒ½ä¼šä»¥ç±»ä¼¼`kubectl apply`çš„æ–¹å¼è‡ªåŠ¨éƒ¨ç½²åˆ° Kubernetes ä¸­ã€‚Traefik ingress controller å°†ä½¿ç”¨ä¸»æœºä¸Šçš„ `80` å’Œ `443` ç«¯å£ï¼ˆå³è¿™äº›ç«¯å£ä¸èƒ½ç”¨äº HostPort æˆ– NodePortï¼‰ã€‚

Traefik å¯ä»¥é€šè¿‡ç¼–è¾‘`traefik.yaml`æ–‡ä»¶è¿›è¡Œé…ç½®ã€‚ä¸ºäº†é˜²æ­¢ k3s ä½¿ç”¨æˆ–è¦†ç›–ä¿®æ”¹åçš„ç‰ˆæœ¬ï¼Œè¯·ä½¿ç”¨`--disable traefik`éƒ¨ç½² k3sï¼Œå¹¶å°†ä¿®æ”¹åçš„å‰¯æœ¬å­˜å‚¨åœ¨`k3s/server/manifests`ç›®å½•ä¸­ã€‚æ›´å¤šä¿¡æ¯è¯·å‚è€ƒå®˜æ–¹çš„ [Traefik é…ç½®å‚æ•°](https://github.com/helm/charts/tree/master/stable/traefik#configuration)ã€‚

âš ï¸è¦ç¦ç”¨ Traefikï¼Œè¯·ä½¿ç”¨`--disable traefik`é€‰é¡¹å¯åŠ¨æ¯ä¸ª serverã€‚

```shell
# ä¼šå‘ç°å¹¶ä¸ä¼šæœ‰è¿›ç¨‹ç›‘å¬80å’Œ443ç«¯å£(Traefik Ingress Controller)
$ netstat -auntlp | grep -E "80|443"
# ä¸»è¦æ˜¯å› ä¸ºTraefikæ²¡æœ‰æŠŠ80å’Œ443ç›‘å¬åˆ°ä¸»æœºä¸Šï¼Œä½†æ˜¯å¹¶ä¸ä¼šå½±å“å…¶åŠŸèƒ½
# Traefikä¸»è¦æ˜¯é€šè¿‡iptablesçš„æ–¹å¼è¿›è¡Œè½¬å‘

# æŸ¥çœ‹iptablesè§„åˆ™
$ iptables -nL -t nat | grep "\<443\>"
CNI-HOSTPORT-SETMARK  tcp  --  10.42.0.0/24         0.0.0.0/0            tcp dpt:443
CNI-HOSTPORT-SETMARK  tcp  --  127.0.0.1            0.0.0.0/0            tcp dpt:443
DNAT       tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:443 to:10.42.0.7:443
CNI-DN-db7ad52b865fb5d94c977  tcp  --  0.0.0.0/0            0.0.0.0/0            /* dnat name: "cbr0" id: "deb7a2b32ae653e362388b98e974787ecb01bea252713f39606707b4980bb850" */ multiport dports 80,443
KUBE-MARK-MASQ  tcp  -- !10.42.0.0/16         10.43.0.1            /* default/kubernetes:https cluster IP */ tcp dpt:443
KUBE-SVC-NPX46M4PTMTKRN6Y  tcp  --  0.0.0.0/0            10.43.0.1            /* default/kubernetes:https cluster IP */ tcp dpt:443
KUBE-MARK-MASQ  tcp  -- !10.42.0.0/16         10.43.205.86         /* kube-system/metrics-server:https cluster IP */ tcp dpt:443
KUBE-SVC-Z4ANX4WAEWEBLCTM  tcp  --  0.0.0.0/0            10.43.205.86         /* kube-system/metrics-server:https cluster IP */ tcp dpt:443
KUBE-MARK-MASQ  tcp  -- !10.42.0.0/16         10.43.154.214        /* kube-system/traefik:websecure cluster IP */ tcp dpt:443
KUBE-SVC-CVG3OEGEH7H5P3HQ  tcp  --  0.0.0.0/0            10.43.154.214        /* kube-system/traefik:websecure cluster IP */ tcp dpt:443
KUBE-FW-CVG3OEGEH7H5P3HQ  tcp  --  0.0.0.0/0            10.0.0.51            /* kube-system/traefik:websecure loadbalancer IP */ tcp dpt:443
KUBE-FW-CVG3OEGEH7H5P3HQ  tcp  --  0.0.0.0/0            10.0.0.52            /* kube-system/traefik:websecure loadbalancer IP */ tcp dpt:44

$ kubectl get pod -o wide -A | grep "10.42.0.7"
kube-system   svclb-traefik-v792h                       2/2     Running     0          3h13m   10.42.0.7    master01   <none>           <none>

$ kubectl exec -it -n kube-system svclb-traefik-v792h -- /bin/sh
Defaulted container "lb-port-80" out of: lb-port-80, lb-port-443
/ # iptables -L -t nat | grep 443
DNAT       tcp  -- !traefik.kube-system.svc.cluster.local  anywhere             tcp dpt:https to:10.43.154.214:443
# å°†Podçš„æµé‡éƒ½è½¬å‘åˆ°äº†10.43.154.214:443åœ°å€ä¸­

# å¯ä»¥æŸ¥çœ‹åˆ°è¯¥10.43.154.214æ˜¯ä¸€ä¸ªServiceçš„åœ°å€
$ kubectl get svc -A | grep 10.43.154.214
kube-system   traefik          LoadBalancer   10.43.154.214   10.0.0.51,10.0.0.52   80:32263/TCP,443:30906/TCP   3h14m
# æ€»ç»“ï¼šTraefiké€šè¿‡è¿™ä¸€ç³»åˆ—çš„è½¬å‘ï¼Œç”±Traefikæ¥å¤„ç†ä¸‹ä¸€è·³çš„æµé‡
```

### 1.2.1 Traefik v1 å¯ç”¨ Dashborad

é»˜è®¤æƒ…å†µä¸‹ï¼ŒK3s 1.20 åŠæ›´æ—©ç‰ˆæœ¬é»˜è®¤å®‰è£… Traefik v1ï¼Œå¹¶ä¸”é»˜è®¤æ²¡æœ‰å¯ç”¨ Traefik Dashboardã€‚å¦‚æœè¦åœ¨ K3s ä¸­å¯ç”¨ Traefik v1 çš„ Dashboradï¼Œæˆ‘ä»¬å¯ä»¥å€ŸåŠ© HelmChartConfig æ¥è‡ªå®šä¹‰ç”± Helm éƒ¨ç½²çš„ Traefik v1 å¹¶å¯ç”¨ Dashboardï¼š

æ³¨æ„ï¼š

- ä¸å»ºè®®æ‰‹åŠ¨ç¼–è¾‘ `/var/lib/rancher/K3s/server/manifests/traefik.yaml` æ¥ä¿®æ”¹ Traefik é…ç½®æ–‡ä»¶ï¼Œå› ä¸º K3s é‡å¯åä¼šè¦†ç›–ä¿®æ”¹çš„å†…å®¹ã€‚
- å»ºè®®é€šè¿‡åœ¨ `/var/lib/rancher/K3s/server/manifests` ä¸­åˆ›å»ºä¸€ä¸ªé¢å¤–çš„ `HelmChartConfig`æ¸…å•æ¥è‡ªå®šä¹‰ Traefik é…ç½®ï¼Œè¯·å‚è€ƒï¼š`http://docs.rancher.cn/docs/K3s/helm/_index/`

```yaml
cat >> /var/lib/rancher/K3s/server/manifests/traefik-config.yaml << EOF
apiVersion: helm.cattle.io/v1
kind: HelmChartConfig
metadata:
  name: traefik
  namespace: kube-system
spec:
  valuesContent: |-
    dashboard:
      enabled: true
      domain: "traefik.localhost"
EOF
```

æ­¤æ—¶ï¼ŒTraefik å°†ä¼šé‡æ–°éƒ¨ç½²ï¼Œå¤§çº¦ 10 ç§’é’Ÿå·¦å³ï¼Œå°±å¯ä»¥é€šè¿‡ `**spec.valuesContent.domain**` é…ç½®çš„åŸŸåæ¥è®¿é—® Traefik Dashboard äº†:

![img](https://cdn.nlark.com/yuque/0/2023/png/2555283/1679844609503-4b54aacf-da8b-4357-a19f-96717f62cdcc.png)

### 1.2.2 å¦‚ä½•å¯ç”¨ Treafik2 dashboardï¼ˆå¯é€‰ï¼‰ï¼š

é»˜è®¤æƒ…å†µä¸‹ï¼ŒK3s 1.21 åŠæ›´é«˜ç‰ˆæœ¬é»˜è®¤å®‰è£… Traefik v2ã€‚å‡ºäºå®‰å…¨è€ƒè™‘ï¼Œé»˜è®¤æ˜¯ä¸å…¬å¼€ Traefik Dashboard çš„ã€‚

```yaml
# treafik2_dashboard.yaml
# Note: in a kubernetes secret the string (e.g. generated by htpasswd) must be base64-encoded first.
# To create an encoded user:password pair, the following command can be used:
# htpasswd -nb admin      admin      | openssl base64
# htpasswd -nb [username] [password] | openssl base64

apiVersion: v1
kind: Secret
metadata:
  name: authsecret
  namespace: default
data:
  users: |2
    YWRtaW46JGFwcjEkLkUweHd1Z0EkUjBmLi85WndJNXZWRFMyR2F2LmtELwoK
---
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  name: traefik-dashboard
spec:
  entryPoints:
    - traefik
  routes:
  - match: Host(`traefik.example.com`) && (PathPrefix(`/api`) || PathPrefix(`/dashboard`))
    kind: Rule
    services:
    - name: api@internal
      kind: TraefikService
    middlewares:
      - name: auth
---
apiVersion: traefik.containo.us/v1alpha1
kind: Middleware
metadata:
  name: auth
spec:
  basicAuth:
    secret: authsecret # Kubernetes secret named "secretName"
$ kubectl create -f treafik2_dashboard.yaml
secret/authsecret created
ingressroute.traefik.containo.us/traefik-dashboard created
middleware.traefik.containo.us/auth created

# æŸ¥çœ‹æœ¬æœºçš„/etc/hostsæ–‡ä»¶
# æ·»åŠ ç›¸åº”çš„æ¡ç›®
10.0.0.51 traefik.example.com
```

ç„¶åé€šè¿‡ http://traefik.example.com/dashboard/ è®¿é—® traefik dashboard

ğŸ‘‘è¦è®¿é—® Traefik ä»ªè¡¨æ¿ï¼Œè¯·æµè§ˆåˆ°ä»¥ä¸‹ URLã€‚æ³¨æ„`**å°¾éƒ¨æ–œæ **`å¾ˆé‡è¦ä¸”éœ€è¦ï¼Œå¦åˆ™æ‚¨å°†æ”¶åˆ°é”™è¯¯404ã€‚

![img](https://cdn.nlark.com/yuque/0/2023/png/2555283/1679846023231-6621e7ff-8deb-4231-bac0-a600a5e55587.png)

### 1.2.3 ğŸ‘‘Traefik v2 å¯ç”¨ Dashborad

é»˜è®¤æƒ…å†µä¸‹ï¼ŒK3s 1.21 åŠæ›´é«˜ç‰ˆæœ¬é»˜è®¤å®‰è£… Traefik v2ã€‚å‡ºäºå®‰å…¨è€ƒè™‘ï¼Œé»˜è®¤æ˜¯ä¸å…¬å¼€ Traefik Dashboard çš„ã€‚æˆ‘ä»¬å¸¸è§çš„å…¬å¼€ Dashborad çš„æ–¹å¼ä¸»è¦ä¸ºä»¥ä¸‹ä¸¤ç§ï¼š

#### 1.2.3.1 **æ–¹æ³• 1ï¼šé€šè¿‡ç«¯å£è½¬å‘æ¥å®ç°**

```shell
kubectl port-forward  -n kube-system $(kubectl get pods -n kube-system| grep '^traefik-' | awk '{print $1}') --address 0.0.0.0 9000:9000
```

ç«¯å£è½¬å‘å¼€å¯åï¼Œå¯ä»¥é€šè¿‡ `http://127.0.0.1:9000/dashboard/` æ¥è®¿é—® Dashboardï¼š

![img](https://cdn.nlark.com/yuque/0/2023/png/2555283/1679846024912-1fc2c368-17f9-4d86-8ab8-53eeb94a5fc9.png)

#### 1.2.3.2 **æ–¹æ³• 2ï¼šè‡ªå®šä¹‰ IngressRoute CRD**

å¦ä¸€ç§æ–¹æ³•æ˜¯é€šè¿‡å®šä¹‰å’Œåº”ç”¨ IngressRoute CRD (`kubectl apply -f dashboard.yaml`)ï¼š

```yaml
# dashboard.yaml
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  name: dashboard
spec:
  entryPoints:
    - web
  routes:
    - match: Host(`traefik.example`) && (PathPrefix(`/dashboard`) || PathPrefix(`/api`))
      kind: Rule
      services:
      - name: api@internal
        kind: TraefikService
```

éƒ¨ç½²æˆåŠŸåï¼Œå¯é€šè¿‡ http://traefik.example/dashboard/ è®¿é—® Dashboardï¼š

![img](https://cdn.nlark.com/yuque/0/2023/png/2555283/1679846026668-4192e851-388c-40ff-871b-df6d20db1944.png)

å‚è€ƒèµ„æ–™ï¼š

https://doc.traefik.io/traefik/operations/dashboard/

https://doc.traefik.io/traefik/middlewares/basicauth/#general

https://www.jianshu.com/p/5e576b4545fc

## 1.3 ğŸ’Service Load Balancer

K3s æä¾›äº†ä¸€ä¸ªåä¸º [Klipper Load Balancer](https://github.com/rancher/klipper-lb) çš„è´Ÿè½½å‡è¡¡å™¨ï¼Œå®ƒå¯ä»¥ä½¿ç”¨å¯ç”¨çš„ä¸»æœºç«¯å£ã€‚ å…è®¸åˆ›å»º LoadBalancer ç±»å‹çš„ Serviceï¼Œä½†ä¸åŒ…æ‹¬ LB çš„å®ç°ã€‚æŸäº› LB æœåŠ¡éœ€è¦äº‘æä¾›å•†ï¼Œä¾‹å¦‚ Amazon EC2 æˆ– Microsoft Azureã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œ`K3s service LB ä½¿å¾—å¯ä»¥åœ¨æ²¡æœ‰äº‘æä¾›å•†çš„æƒ…å†µä¸‹ä½¿ç”¨ LB æœåŠ¡`ã€‚

### 1.3.1 Service LB å¦‚ä½•å·¥ä½œ

K3s åˆ›å»ºäº†ä¸€ä¸ªæ§åˆ¶å™¨ï¼Œè¯¥æ§åˆ¶å™¨ä¸º service load balancer åˆ›å»ºäº†ä¸€ä¸ª Podï¼Œè¿™ä¸ª Pod æ˜¯[Service](https://kubernetes.io/docs/concepts/services-networking/service/)ç±»å‹çš„ Kubernetes å¯¹è±¡ã€‚

å¯¹äºæ¯ä¸ª `service load balancer`ï¼Œéƒ½ä¼šåˆ›å»ºä¸€ä¸ª[DaemonSet](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/)ã€‚ DaemonSet åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šåˆ›å»ºä¸€ä¸ªå‰ç¼€ä¸ºsvcçš„ Podã€‚

Service LB æ§åˆ¶å™¨ä¼šç›‘å¬å…¶ä»– Kubernetes Servicesã€‚å½“å®ƒæ‰¾åˆ°ä¸€ä¸ª Service åï¼Œå®ƒä¼šåœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šä½¿ç”¨ DaemonSet ä¸ºè¯¥æœåŠ¡åˆ›å»ºä¸€ä¸ªä»£ç† Podã€‚è¿™ä¸ª Pod æˆä¸ºå…¶ä»– Service çš„ä»£ç†ï¼Œä¾‹å¦‚ï¼Œæ¥è‡ªèŠ‚ç‚¹ä¸Š 8000 ç«¯å£çš„è¯·æ±‚å¯ä»¥è¢«è·¯ç”±åˆ°ç«¯å£ 8888 ä¸Šçš„å·¥ä½œè´Ÿè½½ã€‚[ ä»£ç† Pod ä¸»è¦çš„ä½œç”¨å°±æ˜¯æŠŠæµé‡è½¬å‘åˆ°å¯¹åº”çš„Workloadä¸­ ]

- å¦‚æœ Service LB è¿è¡Œåœ¨æœ‰å¤–éƒ¨ IP çš„èŠ‚ç‚¹ä¸Šï¼Œåˆ™ä½¿ç”¨å¤–éƒ¨ IPã€‚
- å¦‚æœåˆ›å»ºå¤šä¸ª Servicesï¼Œåˆ™ä¸ºæ¯ä¸ª Service åˆ›å»ºä¸€ä¸ªå•ç‹¬çš„ DaemonSetã€‚
- åªè¦ä½¿ç”¨ä¸åŒçš„ç«¯å£ï¼Œå°±å¯ä»¥åœ¨åŒä¸€èŠ‚ç‚¹ä¸Šè¿è¡Œå¤šä¸ª Servicesã€‚

å¦‚æœæ‚¨å°è¯•åˆ›å»ºä¸€ä¸ªåœ¨ 80 ç«¯å£ä¸Šç›‘å¬çš„ Service LBï¼ŒService LB å°†å°è¯•åœ¨é›†ç¾¤ä¸­æ‰¾åˆ° 80 ç«¯å£çš„ç©ºé—²ä¸»æœºã€‚å¦‚æœè¯¥ç«¯å£æ²¡æœ‰å¯ç”¨çš„ä¸»æœºï¼ŒLB å°†ä¿æŒ Pending çŠ¶æ€ã€‚

### 1.3.2 Service LB ç”¨æ³•

åœ¨ K3s ä¸­åˆ›å»ºä¸€ä¸ª [LoadBalancer ç±»å‹çš„ Service](https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer)ã€‚

```yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name:  nginx-deployment
  namespace: default
  labels:
    app: nginx
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name:  nginx
        image: kingsd/nginx:install-tools
        ports:
        - containerPort: 80
          name: nginx-port
---
apiVersion: v1
kind: Service
metadata:
  name: nginx
  namespace: default
spec:
  selector:
    app: nginx
  type: LoadBalancer
  ports:
  - name: nginx
    protocol: TCP
    port: 8888
    targetPort: nginx-port
$ kubectl create -f nginx-loadbalancer.yaml
deployment.apps/nginx-deployment created
service/nginx created

# svclbæ˜¯åˆ†åˆ«éƒ¨ç½²åˆ°ä¸¤ä¸ªèŠ‚ç‚¹ä¸­
$ kubectl get pod -o wide
NAME                                READY   STATUS    RESTARTS   AGE    IP           NODE   NOMINATED NODE   READINESS GATES
svclb-nginx-wffxt                   1/1     Running   0          119s   10.42.0.17   k3s1   <none>           <none>
nginx-deployment-6b769f4497-x82sp   1/1     Running   0          119s   10.42.0.16   k3s1   <none>           <none>
svclb-nginx-s5jqw                   1/1     Running   0          119s   10.42.1.4    k3s2   <none>           <none
[......]

$ kubectl get svc nginx
NAME    TYPE           CLUSTER-IP     EXTERNAL-IP           PORT(S)          AGE
nginx   LoadBalancer   10.43.92.152   10.0.0.51,10.0.0.52   8888:30285/TCP   40s

$ curl 10.0.0.51:8888 # curl 10.0.0.52:8888 æ•ˆæœæ˜¯ä¸€æ ·çš„
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
# æŸ¥çœ‹ç›¸åº”çš„é˜²ç«å¢™æµé‡è½¬å‘ç­–ç•¥
$ iptables -vnL -t nat | grep "8888"
    0     0 CNI-HOSTPORT-SETMARK  tcp  --  *      *       10.42.0.0/24         0.0.0.0/0            tcp dpt:8888
    0     0 CNI-HOSTPORT-SETMARK  tcp  --  *      *       127.0.0.1            0.0.0.0/0            tcp dpt:8888
    0     0 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:8888 to:10.42.0.17:8888
    0     0 CNI-DN-0313432e9c8f2f5b81fd0  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            /* dnat name: "cbr0" id: "3402365beb39d9f523f6cde07f2915c127643effe8473ec0c82cb077ea3d0eb0" */ multiport dports 8888
    0     0 KUBE-MARK-MASQ  tcp  --  *      *      !10.42.0.0/16         10.43.16.201         /* default/nginx:nginx cluster IP */ tcp dpt:8888
    0     0 KUBE-SVC-GFECHBCWDTHJWART  tcp  --  *      *       0.0.0.0/0            10.43.16.201         /* default/nginx:nginx cluster IP */ tcp dpt:8888
    0     0 KUBE-FW-GFECHBCWDTHJWART  tcp  --  *      *       0.0.0.0/0            10.0.0.51            /* default/nginx:nginx loadbalancer IP */ tcp dpt:8888
    0     0 KUBE-FW-GFECHBCWDTHJWART  tcp  --  *      *       0.0.0.0/0            10.0.0.52            /* default/nginx:nginx loadbalancer IP */ tcp dpt:8888
$ kubectl get pod -o wide -A | grep 10.42.0.17
default       svclb-nginx-wffxt                         1/1     Running     0          3m3s   10.42.0.17   k3s1   <none>           <none>

$ kubectl exec -it svclb-nginx-wffxt -- /bin/sh -c 'iptables -L -t nat | grep "8888"'
DNAT       tcp  -- !nginx.default.svc.cluster.local  anywhere             tcp dpt:8888 to:10.43.16.201:8888

$ kubectl get svc | grep "10.43.16.201"
nginx        LoadBalancer   10.43.16.201   10.0.0.51,10.0.0.52   8888:30467/TCP   3m52s

# æŸ¥çœ‹Serviceçš„è¯¦ç»†ä¿¡æ¯æ˜¾ç¤º
$ kubectl describe svc nginx
Name:                     nginx
Namespace:                default
Labels:                   <none>
Annotations:              <none>
Selector:                 app=nginx
Type:                     LoadBalancer
IP Family Policy:         SingleStack
IP Families:              IPv4
IP:                       10.43.16.201
IPs:                      10.43.16.201
LoadBalancer Ingress:     10.0.0.51, 10.0.0.52
Port:                     nginx  8888/TCP
TargetPort:               nginx-port/TCP
NodePort:                 nginx  30467/TCP
Endpoints:                10.42.0.16:80
Session Affinity:         None
External Traffic Policy:  Cluster
Events:                   <none>
# æŸ¥çœ‹ Endpoints è¯¦ç»†ä¿¡æ¯æ˜¾ç¤º
$ kubectl describe endpoints nginx
Name:         nginx
Namespace:    default
Labels:       <none>
Annotations:  endpoints.kubernetes.io/last-change-trigger-time: 2023-03-27T00:07:11+08:00
Subsets:
  Addresses:          10.42.0.16
  NotReadyAddresses:  <none>
  Ports:
    Name   Port  Protocol
    ----   ----  --------
    nginx  80    TCP

Events:  <none>

$ kubectl get pod -o wide | grep "10.42.0.16"
nginx-deployment-6b769f4497-x82sp   1/1     Running   0          4m46s   10.42.0.16   k3s1   <none>           <none
```

### 1.3.3 ğŸ“ä»èŠ‚ç‚¹ä¸­æ’é™¤ Service LB

è¦æ’é™¤èŠ‚ç‚¹ä½¿ç”¨ Service LBï¼Œè¯·å°†ä»¥ä¸‹æ ‡ç­¾æ·»åŠ åˆ°ä¸åº”æ’é™¤çš„èŠ‚ç‚¹ä¸Šï¼š

```shell
svccontroller.k3s.cattle.io/enablelb
```

å¦‚æœä½¿ç”¨æ ‡ç­¾ï¼Œåˆ™ `service load balancer` ä»…åœ¨æ ‡è®°çš„èŠ‚ç‚¹ä¸Šè¿è¡Œã€‚

```shell
# æŸ¥çœ‹Nodeçš„æ ‡ç­¾
$ kubectl get nodes --show-labels
NAME   STATUS   ROLES                  AGE     VERSION         LABELS
k3s2   Ready    <none>                 3m23s   v1.21.14+k3s1   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=k3s,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k3s2,kubernetes.io/os=linux,node.kubernetes.io/instance-type=k3s
k3s1   Ready    control-plane,master   164m    v1.21.14+k3s1   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=k3s,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k3s1,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=true,node-role.kubernetes.io/master=true,node.kubernetes.io/instance-type=k3s
# è®¾ç½®Nodeçš„æ ‡ç­¾
$ kubectl label node k3s2 svccontroller.k3s.cattle.io/enablelb=true
node/k3s2 labeled

# å†æ¬¡æŸ¥çœ‹Nodeçš„æ ‡ç­¾
$ kubectl get nodes --show-labels
NAME   STATUS   ROLES                  AGE     VERSION         LABELS
k3s1   Ready    control-plane,master   164m    v1.21.14+k3s1   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=k3s,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k3s1,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=true,node-role.kubernetes.io/master=true,node.kubernetes.io/instance-type=k3s
k3s2   Ready    <none>                 3m56s   v1.21.14+k3s1   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=k3s,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k3s2,kubernetes.io/os=linux,node.kubernetes.io/instance-type=k3s,svccontroller.k3s.cattle.io/enablelb=true

# ä¼šå‘ç°å·²ç»æ²¡æœ‰k3s2çš„svclbçš„Pod
$ kubectl get pods -o wide | grep "svclb-nginx"
svclb-nginx-fznbq                   1/1     Running   0          35s    10.42.1.7    k3s2   <none>           <none>
```

### 1.3.4 ğŸ“ç¦ç”¨ Service LB

è¦ç¦ç”¨åµŒå…¥å¼ LBï¼Œè¯·ä½¿ç”¨`--disable servicelb`é€‰é¡¹è¿è¡Œ k3s serverã€‚

å¦‚æœæ‚¨å¸Œæœ›è¿è¡Œå…¶ä»– LBï¼Œä¾‹å¦‚ MetalLB [ å››å±‚è´Ÿè½½å‡è¡¡å™¨ ] ï¼Œè¿™æ˜¯å¿…éœ€çš„ã€‚

## 1.4 æ²¡æœ‰ä¸»æœºåçš„èŠ‚ç‚¹

ä¸€äº›äº‘æä¾›å•†ï¼ˆå¦‚ Linodeï¼‰ä¼šä»¥ "`localhost` "ä½œä¸ºä¸»æœºååˆ›å»ºæœºå™¨ï¼Œè€Œå…¶ä»–æä¾›å•†å¯èƒ½æ ¹æœ¬æ²¡æœ‰è®¾ç½®ä¸»æœºåã€‚è¿™å¯èƒ½ä¼šå¯¼è‡´åŸŸåè§£æçš„é—®é¢˜ã€‚ä½ å¯ä»¥ç”¨`--node-name`æ ‡å¿—æˆ–`K3S_NODE_NAME`ç¯å¢ƒå˜é‡æ¥è¿è¡Œ K3sï¼Œè¿™æ ·å°±ä¼šä¼ é€’èŠ‚ç‚¹åç§°æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

- `æŒ‡å®šä¸»æœºå`ï¼š

```bash
# K3S_URL : æŒ‡å®šK3s Master URL
# K3S_TOKEN : æŒ‡å®šK3s Master Token[cat /var/lib/rancher/k3s/server/token]
$ curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \
  INSTALL_K3S_MIRROR=cn \
  K3S_URL=https://10.0.0.51:6443 \ 
  K3S_TOKEN=rancher sh -s - --node-name k3s2
# K3S_URL : æŒ‡å®šK3s Master URL
# K3S_TOKEN : æŒ‡å®šK3s Master Token[cat /var/lib/rancher/k3s/server/token]
# ä½¿ç”¨ç¯å¢ƒå˜é‡çš„æ–¹å¼æŒ‡å®šä¸»æœºåæœ€åè¿˜æ˜¯ä¼šä»¥å‚æ•°çš„å½¢å¼è¿›è¡Œä¿®æ”¹
$ curl -sfL https://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \
  K3S_NODE_NAME="k3s2" \
  INSTALL_K3S_MIRROR=cn \
  K3S_URL=https://10.0.0.51:6443 \
  K3S_TOKEN=rancher sh -
$ kubectl get nodes
NAME   STATUS   ROLES                  AGE   VERSION
k3s1   Ready    control-plane,master   72m   v1.25.6+k3s1
k3s2   Ready    <none>                 28s   v1.25.6+k3s1
```